{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SB3-KukaDiverseObjectEnv.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uM47Z8DXHCOK",
        "2e5bkx64V5EI",
        "qBHuIj1QZfkC"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWJWVRh7G01V"
      },
      "source": [
        "# Experimenting with Stable Baselines3\n",
        "\n",
        "Environments to be tried:\n",
        "\n",
        "- KukaDiverseObjectEnv\n",
        "- KukaGrasp\n",
        "- RaceCar\n",
        "- Panda-Gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbSEmpx2G92j"
      },
      "source": [
        "## Installation\n",
        "\n",
        "- install pybullet and stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yel0C8bMMae3"
      },
      "source": [
        "!pip install stable-baselines3[extra] > /dev/null 2>&1\n",
        "!pip install pybullet > /dev/null 2>&1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BjDE4Cbaw2a"
      },
      "source": [
        "## Check GPU & Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIBikvPU1trn"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUB5ZbkLbA_f"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOzDVh-DJbzb"
      },
      "source": [
        "## Set up Google Drive \n",
        "- For storing outputs / results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CovNIE1cJf6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdda5b29-0b9c-45ba-88b7-fa4446edee4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM47Z8DXHCOK"
      },
      "source": [
        "## CartPole Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I20BawieNOLv"
      },
      "source": [
        "import gym\n",
        "from stable_baselines3 import A2C\n",
        "env = gym.make('CartPole-v1')\n",
        "model = A2C('MlpPolicy', env, verbose=1)\n",
        "model.learn(total_timesteps=50000)\n",
        "\n",
        "# obs = env.reset()\n",
        "# for i in range(1000):\n",
        "#   action, _state = model.predict(obs, deterministic=True)\n",
        "#   obs, reward, done, info = env.step(action)\n",
        "#   env.render()\n",
        "#   if done:\n",
        "#     obs = env.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e5bkx64V5EI"
      },
      "source": [
        "## Displaying Gym Animations\n",
        "- Atari animations have some problems. Need to be fixed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNWywLQCO_fu"
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "#!pip install gym[atari] > /dev/null 2>&1   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_njY0-KPAZO"
      },
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment \n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5v8KRMNTo0e"
      },
      "source": [
        "#env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
        "#env = wrap_env(gym.make(\"Atlantis-v0\"))  # does not work\n",
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "obs = env.reset()\n",
        "for i in range(1000):\n",
        "  env.render()\n",
        "  #your agent goes here\n",
        "  #action = env.action_space.sample() \n",
        "  # trained agent\n",
        "  action, _state = model.predict(obs, deterministic=True)\n",
        "        \n",
        "  obs, reward, done, info = env.step(action) \n",
        "  \n",
        "  if done: \n",
        "    obs = env.reset()\n",
        "          \n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBHuIj1QZfkC"
      },
      "source": [
        "## HalfCheetahBulletEnv-v0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsmYBEVCZefD"
      },
      "source": [
        "import os\n",
        "import gym\n",
        "import pybullet_envs\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "\n",
        "env = DummyVecEnv([lambda: gym.make(\"HalfCheetahBulletEnv-v0\")])\n",
        "\n",
        "# Automatically normalize the input features and rewards\n",
        "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)\n",
        "model = PPO('MlpPolicy', env)\n",
        "model.learn(total_timesteps=2000)\n",
        "\n",
        "# Don't forget to save the VecNormalize statistics when saving the agent\n",
        "log_dir = \"/tmp/\"\n",
        "model.save(log_dir + \"ppo_halfcheetah\")\n",
        "stats_path = os.path.join(log_dir, \"vec_normalize.pkl\")\n",
        "env.save(stats_path)\n",
        "\n",
        "# To demonstrate loading\n",
        "del model, env\n",
        "\n",
        "# Load saved statistics\n",
        "env = DummyVecEnv([lambda: gym.make(\"HalfCheetahBulletEnv-v0\")])\n",
        "env = VecNormalize.load(stats_path, env)\n",
        "# do not update them at test time\n",
        "env.training = False\n",
        "# reward normalization is not needed at test time\n",
        "env.norm_reward = False\n",
        "\n",
        "# Load the agent\n",
        "model = PPO.load(log_dir + \"ppo_halfcheetah\", env=env)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEKWq8ijJcnX"
      },
      "source": [
        "# Test\n",
        "env = wrap_env(gym.make('HalfCheetahBulletEnv-v0'))\n",
        "obs = env.reset()\n",
        "for i in range(100):\n",
        "  env.render()\n",
        "  action, _ = model.predict(obs)\n",
        "  obs, reward, done, _ = env.step(action) \n",
        "  if done:\n",
        "    env.reset()\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pu6c-MaKLwP"
      },
      "source": [
        "## Wrappers \n",
        "- Change Image Format and Normalize Pixels\n",
        "- TimeLimitWrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIn6xo5MMQeL"
      },
      "source": [
        "### Normalize Observation Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHsnbyMg1ZZc"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "class NormalizeObsvnWrapper(gym.Wrapper):\n",
        "  \"\"\"\n",
        "  :param env: (gym.Env)   Gym environment that will be wrapped\n",
        "  \"\"\"\n",
        "  def __init__(self, env):\n",
        "    assert isinstance(env.observation_space, gym.spaces.Box),\\\n",
        "     \"Valid for continuous observation spaces of type gym.spaces.Box\"\n",
        "\n",
        "    self._height = env.observation_space.shape[0]\n",
        "    self._width = env.observation_space.shape[1]\n",
        "    self._channels = env.observation_space.shape[2]\n",
        "\n",
        "    env.observation_space = gym.spaces.Box(low=0, high=255,\n",
        "                                            shape=(self._channels, \n",
        "                                                   self._height,\n",
        "                                                   self._width))\n",
        "    env.reward_range = (-np.inf, np.inf)\n",
        "    # call the parent constructor so that we can access self.env\n",
        "    super(NormalizeObsvnWrapper, self).__init__(env)\n",
        "    self.env.reward_range = (-np.inf, np.inf)\n",
        "\n",
        "\n",
        "  def _modify_obsvn(self, obs):\n",
        "    new_obs = np.transpose(obs, (2, 0, 1))\n",
        "    new_obs = np.asarray(new_obs, dtype=np.float32) / 255.0\n",
        "    return new_obs\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    Convert Images from HxWxC format to CxHxW\n",
        "    Normalize the pixels between 0 and 1.0\n",
        "    \"\"\"\n",
        "    return self._modify_obsvn(self.env.reset())\n",
        "  \n",
        "  def step(self, action):\n",
        "    obs, reward, done, info = self.env.step(action)\n",
        "    new_obs = self._modify_obsvn(obs)\n",
        "    info['channel_first'] = True\n",
        "    info['nomalize pixel'] = True\n",
        "    return new_obs, reward, done, info\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISE2NqAPaDIZ"
      },
      "source": [
        "# Testing the above wrapper\n",
        "import pybullet as p\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "\n",
        "p.connect(p.DIRECT)\n",
        "env = NormalizeObsvnWrapper(KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                           removeHeightHack=False))\n",
        "check_env(env)\n",
        "\n",
        "obs = env.reset()\n",
        "print('shape of observation space:', env.observation_space.shape)\n",
        "print('shape of observation:', np.shape(obs))\n",
        "\n",
        "p.disconnect(p.DIRECT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6J_4KKbMWlI"
      },
      "source": [
        "### Time Limit Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aNymhlEMf7V"
      },
      "source": [
        "import gym\n",
        "class TimeLimitWrapper(gym.Wrapper):\n",
        "  \"\"\"\n",
        "  :param env: (gym.env) gym environment that will be wrapped\n",
        "  :param max_steps: (int) max number of steps per episode\n",
        "  \"\"\"\n",
        "  def __init__(self, env, max_steps=100):\n",
        "    # call the parent constructor, so we can access self.env later\n",
        "    super(TimeLimitWrapper, self).__init__(env)\n",
        "    self.max_steps = max_steps\n",
        "    # counter of steps per episode\n",
        "    self.current_step = 0\n",
        "\n",
        "  def reset(self):\n",
        "    \"\"\"\n",
        "    Reset the environment\n",
        "    \"\"\"\n",
        "    self.current_step = 0\n",
        "    return self.env.reset()\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"\n",
        "    :param action: ([float] or int) Action taken by the agent\n",
        "    :return: (np.ndarray, float, bool, dict) observation, reward, done and info\n",
        "    \"\"\"\n",
        "    self.current_step += 1\n",
        "    obs, reward, done, info = self.env.step(action)\n",
        "    if self.current_step >= self.max_steps:\n",
        "      done = True\n",
        "      # update info dict to signal that the limit was exceeded\n",
        "      info['time_limit_reached'] = True\n",
        "    return obs, reward, done, info\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVqS5Y0wMo-8"
      },
      "source": [
        "# Test the wrapper\n",
        "import pybullet as p\n",
        "from pybullet_envs.bullet.racecarZEDGymEnv import RacecarZEDGymEnv\n",
        "\n",
        "p.connect(p.DIRECT)\n",
        "env = RacecarZEDGymEnv(isDiscrete=False, renders=False)\n",
        "env = TimeLimitWrapper(env, max_steps=20)\n",
        "\n",
        "for ep in range(5):\n",
        "  obs = env.reset()\n",
        "  t = 0\n",
        "  ep_reward = 0\n",
        "  while True:\n",
        "    action = env.action_space.sample()\n",
        "    next_obs, reward, done, info = env.step(action)\n",
        "    t += 1\n",
        "    ep_reward += reward\n",
        "\n",
        "    if done:\n",
        "      print('Episode:{}, steps:{}, Score:{}'.format(ep, t, ep_reward))\n",
        "      break\n",
        "    \n",
        "p.disconnect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaDQX2tyMvYa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llcmeiomMvkP"
      },
      "source": [
        "## Callbacks\n",
        "- SaveOnBestTrainingRewardCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "180_fRp_rKMa"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMju2JR1oT-Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "outputId": "fbec9a24-ea3b-431a-ee67-e00ecfd41da8"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir '/content/gdrive/My Drive/Colab/SB3/kuka/tb_log/'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbqsEj3M58Z3"
      },
      "source": [
        "## PyBullet KukaDiverseObject Environment\n",
        "\n",
        "- Use Stable Baselines3 (SB3) Algorithm SAC or PPO to solve this problem.\n",
        "- First Convert image to channel first format & normalize the pixels.\n",
        "- Create a Custom Feature Extractor.\n",
        "- Define the `net_arch` parameter \n",
        "- Then create and train the SAC model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZDDboDBvr_j"
      },
      "source": [
        "### Custom CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIfCH_Tv-BbU"
      },
      "source": [
        "import gym\n",
        "import torch as th\n",
        "\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "\n",
        "class CustomCNN(BaseFeaturesExtractor):\n",
        "  \"\"\"\n",
        "  :param observation_space: (gym.space)\n",
        "  :param features_dim: (int) number of features extracted. This corresponds to \n",
        "        the number of unit for the last layer\n",
        "  \"\"\"\n",
        "  def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):\n",
        "    super(CustomCNN, self).__init__(observation_space, features_dim)\n",
        "    # We assume CxHxW images (channels first format)\n",
        "    n_input_channels = observation_space.shape[0]\n",
        "    self.cnn = th.nn.Sequential(\n",
        "        th.nn.Conv2d(n_input_channels, 16, kernel_size=2, stride=2, padding=0),\n",
        "        th.nn.ReLU(),\n",
        "        th.nn.BatchNorm2d(16),\n",
        "        th.nn.Conv2d(16, 32, kernel_size=2, stride=2, padding=0),\n",
        "        th.nn.ReLU(),\n",
        "        th.nn.BatchNorm2d(32),\n",
        "        th.nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0),\n",
        "        th.nn.ReLU(),\n",
        "        th.nn.BatchNorm2d(32),\n",
        "        th.nn.Flatten()\n",
        "    )\n",
        "\n",
        "    # compute shape by doing one forward pass\n",
        "    with th.no_grad():\n",
        "      n_flatten = self.cnn(\n",
        "          th.as_tensor(observation_space.sample()[None]).float()\n",
        "      ).shape[1]\n",
        "\n",
        "    self.linear = th.nn.Sequential(\n",
        "        th.nn.Linear(n_flatten, 128), \n",
        "        th.nn.ReLU(),\n",
        "        th.nn.Linear(128, 128),\n",
        "        th.nn.ReLU(),\n",
        "        th.nn.Linear(128, features_dim),\n",
        "        th.nn.ReLU()\n",
        "        ) \n",
        "\n",
        "  def forward(self, observations: th.Tensor) -> th.Tensor:\n",
        "    return self.linear(self.cnn(observations))\n",
        "\n",
        "  \n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6P9nFS0vn2R"
      },
      "source": [
        "### SAC\n",
        "\n",
        "- Single processing works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iUW-HgiilaY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "7564876c-50ae-451d-b498-32ddc4d13bd6"
      },
      "source": [
        "import os\n",
        "import pybullet as p\n",
        "import gym\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "from stable_baselines3 import SAC, PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "\n",
        "# create Directories\n",
        "root_path = '/content/gdrive/My Drive/Colab/SB3/kuka/'\n",
        "model_path = root_path + 'best_model/sac/'\n",
        "result_path = root_path + 'eval_results/sac/'\n",
        "monitor_path = root_path + 'monitor/sac/'\n",
        "tb_log_path = root_path + 'tb_log/'\n",
        "checkpt_path = root_path + 'checkpoints/sac/'\n",
        "\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "os.makedirs(result_path, exist_ok=True)\n",
        "os.makedirs(tb_log_path, exist_ok=True)\n",
        "os.makedirs(monitor_path, exist_ok=True)\n",
        "os.makedirs(checkpt_path, exist_ok=True)\n",
        "\n",
        "p.connect(p.DIRECT)\n",
        "\n",
        "# create the environment\n",
        "env = NormalizeObsvnWrapper(KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                          removeHeightHack=False))\n",
        "env = Monitor(env, monitor_path)\n",
        "\n",
        "# environment for periodic evaluation\n",
        "eval_env = NormalizeObsvnWrapper(KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                          removeHeightHack=False))\n",
        "eval_env = Monitor(eval_env, monitor_path)\n",
        "\n",
        "\n",
        "\n",
        "#callbacks\n",
        "\n",
        "eval_callback = EvalCallback(eval_env, best_model_save_path=root_path+'best_model/',\n",
        "                             log_path=root_path+'results/', eval_freq=500,\n",
        "                             deterministic=True, render=False)\n",
        "\n",
        "checkpoint_callback = CheckpointCallback(save_freq=5000, save_path=checkpt_path, name_prefix='kuka_sac_checkpt')\n",
        "\n",
        "callback_list = CallbackList([checkpoint_callback, eval_callback])\n",
        "\n",
        "\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class = CustomCNN,\n",
        "    features_extractor_kwargs = dict(features_dim=64),\n",
        "    net_arch = dict(qf=[128, 64, 32], pi=[128, 64, 64])\n",
        ")\n",
        "\n",
        "model = SAC('CnnPolicy', env, buffer_size=100000, batch_size=256,\n",
        "            policy_kwargs=policy_kwargs, tensorboard_log=tb_log_path)\n",
        "\n",
        "# train the model: 50K time steps is adequate\n",
        "%time model.learn(total_timesteps=50000, log_interval=4, tb_log_name='kuka_sac', callback=callback_list)\n",
        "\n",
        "\n",
        "mean, std = evaluate_policy(model, env, n_eval_episodes=50, deterministic=True)\n",
        "print('Evaluate the model after training: {} +/- {}'.format(mean, std))\n",
        "\n",
        "p.disconnect(p.DIRECT)\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-7f02931837ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# train the model: 50K time steps is adequate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time model.learn(total_timesteps=50000, log_interval=4, tb_log_name='kuka_sac', callback=callback_list)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         )\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mlearning_starts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_starts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             )\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0;31m# Rescale and perform action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                 \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/vec_normalize.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mwhere\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0meach\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \"\"\"\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-33a0dbda3c6a>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mnew_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modify_obsvn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channel_first'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pybullet_envs/bullet/kuka_diverse_object_gym_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_step_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pybullet_envs/bullet/kuka_diverse_object_gym_env.py\u001b[0m in \u001b[0;36m_step_continuous\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mgrasp_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinger_angle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kuka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplyAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrasp_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepSimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;31m#if self._renders:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m#  time.sleep(self._timeStep)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l06ci-AhuTAF"
      },
      "source": [
        "### Use checkpoints to restart training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PJK21Xoucue"
      },
      "source": [
        "# create the environment\n",
        "env = NormalizeObsvnWrapper(KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                           removeHeightHack=False))\n",
        "\n",
        "env = Monitor(env, monitor_path)    # not sure if needed\n",
        "\n",
        "# load checkpoints\n",
        "loaded_model = SAC.load(checkpt_path+'kuka_sac_checkpt_6000', verbose=1)\n",
        "\n",
        "# continue training\n",
        "model.learn(total_timesteps=100000, log_interval=4, tb_log_name='kuka_sac', callback=callback_list)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuSMP2SFtTc4"
      },
      "source": [
        "### Load models and test it\n",
        "- Image save does not work on Colab as the flag `render=True` requests for xserver which is not available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlyEeCvJtZLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb31bcd4-ccca-4c40-b9ab-96a0caafae48"
      },
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "import os\n",
        "import pybullet as p\n",
        "import gym\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "from stable_baselines3 import SAC, PPO\n",
        "\n",
        "\n",
        "p.connect(p.DIRECT)\n",
        "\n",
        "\n",
        "# create the environment - Enable the render flag\n",
        "env = NormalizeObsvnWrapper(KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                           removeHeightHack=False))\n",
        "\n",
        "# load best model\n",
        "loaded_model = SAC.load(model_path+'best_model', verbose=1)\n",
        "\n",
        "print('Best Model loaded')\n",
        "\n",
        "# test / render\n",
        "\n",
        "scores = []\n",
        "# images = []\n",
        "# img = env.render(mode='rgb_array')\n",
        "for ep in range(10):\n",
        "  obs = env.reset()     # normalized pixesl, CHW format\n",
        "  t = 0\n",
        "  ep_reward = 0\n",
        "  while True:\n",
        "    action, _ = loaded_model.predict(obs)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    # img = env.render(mode='rgb_array')\n",
        "    # images.append(img)\n",
        "    ep_reward += reward\n",
        "    t += 1\n",
        "    if done:\n",
        "      scores.append(ep_reward)\n",
        "      print(f\"Episode: {ep}, Steps: {t}, Reward: {ep_reward}\")\n",
        "      break\n",
        "\n",
        "print(\"Mean episodic score: {:.2f}\".format(np.mean(scores)))\n",
        "\n",
        "# imageio.save(video_path+'kuka_sac.gif', np.array(images), fps=2)\n",
        "\n",
        "p.disconnect(p.DIRECT)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Model loaded\n",
            "Episode: 0, Steps: 7, Reward: 1\n",
            "Episode: 1, Steps: 7, Reward: 0\n",
            "Episode: 2, Steps: 7, Reward: 0\n",
            "Episode: 3, Steps: 7, Reward: 0\n",
            "Episode: 4, Steps: 7, Reward: 0\n",
            "Episode: 5, Steps: 7, Reward: 0\n",
            "Episode: 6, Steps: 7, Reward: 1\n",
            "Episode: 7, Steps: 7, Reward: 0\n",
            "Episode: 8, Steps: 7, Reward: 0\n",
            "Episode: 9, Steps: 7, Reward: 0\n",
            "Mean episodic score: 0.20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1F-7jwq5_sM"
      },
      "source": [
        "import pybullet as p\n",
        "import imageio\n",
        "import gym\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "from torchsummary import summary\n",
        "\n",
        "p.connect(p.DIRECT)\n",
        "\n",
        "#############\n",
        "log_dir = \"/tmp/gym/\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "checkpoint_callback = CheckpointCallback(save_freq=100, save_path=log_dir,\n",
        "                                         name_prefix='kuka_sac')\n",
        "\n",
        "\n",
        "env = KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                           removeHeightHack=False)\n",
        "\n",
        "# env = DummyVecEnv([lambda:KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "#                             removeHeightHack=False) ])\n",
        "# env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
        "\n",
        "env = Monitor(env, log_dir)\n",
        "\n",
        "print('shape of Observation space: ', env.observation_space.shape)\n",
        "print('shape of Action space: ', env.action_space.shape)\n",
        "#print('Reward Range: ', env.reward_range)\n",
        "print('Action High value: ', env.action_space.high)\n",
        "print('Action Low Value: ', env.action_space.low)\n",
        "\n",
        "# create SAC model\n",
        "model = SAC('MlpPolicy', env, verbose=0, buffer_size=100000, batch_size=256,\n",
        "            tensorboard_log=tb_log_path)\n",
        "\n",
        "model_param = model.get_parameters()\n",
        "for key,value in model_param.items():\n",
        "  print(key, len(value))\n",
        "\n",
        "print('type of model[policy]', type(model_param['policy']))\n",
        "for key, value in model_param['policy'].items():\n",
        "  print(key, np.shape(value))\n",
        "\n",
        "# mean, std = evaluate_policy(model, env, n_eval_episodes=10, deterministic=True)\n",
        "# print('Evaluate the model before training: {} +/- {}'.format(mean, std))\n",
        "\n",
        "\n",
        "# train the model\n",
        "# %time model.learn(total_timesteps=100000, log_interval=4, tb_log_name='first_run', callback=checkpoint_callback)\n",
        "\n",
        "\n",
        "# mean, std = evaluate_policy(model, env, n_eval_episodes=10, deterministic=True)\n",
        "# print('Evaluate the model after training: {} +/- {}'.format(mean, std))\n",
        "\n",
        "\n",
        "p.disconnect(p.DIRECT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxJdjT2lhlra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7dc93c-e949-464d-96ed-fca709c4d5c3"
      },
      "source": [
        "import pybullet as p\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "\n",
        "p.connect(p.DIRECT)\n",
        "# Record the video starting from the first step\n",
        "video_folder = 'logs/videos/'\n",
        "\n",
        "video_length = 100\n",
        "\n",
        "# create the environment - Enable the render flag\n",
        "env = DummyVecEnv([lambda:KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                            removeHeightHack=False) ])\n",
        "\n",
        "env = VecVideoRecorder(env, video_folder,\n",
        "                       record_video_trigger=lambda x: x==0,\n",
        "                       video_length=video_length,\n",
        "                       name_prefix=\"random-agent-kuka\")\n",
        "\n",
        "obs = env.reset()\n",
        "for _ in range(video_length):\n",
        "    action = [env.action_space.sample()]\n",
        "    #action = model.predict(obsv, deterministic=True)\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "env.close()\n",
        "p.disconnect(p.DIRECT)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving video to /content/logs/videos/random-agent-kuka-step-0-to-step-100.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyYz1we5hlGC"
      },
      "source": [
        "# Test\n",
        "import pybullet as p\n",
        "import time\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "p.connect(p.DIRECT)\n",
        "\n",
        "env = wrap_env(KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=True,\n",
        "                            removeHeightHack=False))\n",
        "\n",
        "obs = env.reset()\n",
        "for i in range(100):\n",
        "  env.render()\n",
        "  action = env.action_space.sample()\n",
        "  obs, reward, done, _ = env.step(action)\n",
        "  if done:\n",
        "    obs = env.reset()\n",
        "env.close()\n",
        "p.disconnect()\n",
        "show_video()\n",
        "p.disconnect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvQXZ16l0Cd2"
      },
      "source": [
        "nd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR62qHLuvHhd"
      },
      "source": [
        "### Generating Plots\n",
        "- read `monitor.csv` file from `monitor_path`\n",
        "- Use `pandas.dataframe` to analyse data and generate plots\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJk1EVqDx3GT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54838d94-ef95-4c22-b93f-d065b087802e"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# read CSV file while skipping the first row and using the second row as headers\n",
        "# don't use the first column as index.\n",
        "df = pd.read_csv(monitor_path+'monitor.csv', skiprows=0, header=1, index_col=None)\n",
        "\n",
        "print('datatype:', type(df))\n",
        "print(df.shape)\n",
        "# data preview\n",
        "print(df.head())\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "# cumulative sum\n",
        "print(df['r'].cumsum(axis=0))\n",
        "\n",
        "df['cumr'] = df['r'].cumsum(axis=0)\n",
        "df['ep_r'] = df['cumr'] / (df.index + 1)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "total_episodes = df.shape[0]\n",
        "print('-----------------------')\n",
        "print('Total Number of episodes: ', total_episodes)\n",
        "print('Average Episodic Reward:', df['r'].sum(axis=0) / total_episodes)\n",
        "print('Mean Episode Length:', df['l'].mean())\n",
        "print('----------------------')\n",
        "plt.figure(0)\n",
        "g1 = df['l'].plot()\n",
        "g1.set_xlabel('Episodes')\n",
        "g1.set_ylabel('Episode Length')\n",
        "\n",
        "plt.figure(1)\n",
        "g2 = df['ep_r'].plot(linewidth=3, color='red')\n",
        "g2.set_xlabel('Episodes')\n",
        "g2.set_ylabel('Mean Episodic Reward')\n",
        "# plt.plot(x = 'Index', y='ep_r', data=df, color='red', linewidth=2)\n",
        "# plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datatype: <class 'pandas.core.frame.DataFrame'>\n",
            "(13795, 3)\n",
            "   r  l           t\n",
            "0  0  7  259.833267\n",
            "1  1  7  262.451356\n",
            "2  1  7  264.999990\n",
            "3  1  7  267.518090\n",
            "4  0  7  269.904530\n",
            "Index(['r', 'l', 't'], dtype='object')\n",
            "0           0\n",
            "1           1\n",
            "2           2\n",
            "3           3\n",
            "4           3\n",
            "         ... \n",
            "13790    6108\n",
            "13791    6108\n",
            "13792    6109\n",
            "13793    6109\n",
            "13794    6109\n",
            "Name: r, Length: 13795, dtype: int64\n",
            "   r  l           t  cumr      ep_r\n",
            "0  0  7  259.833267     0  0.000000\n",
            "1  1  7  262.451356     1  0.500000\n",
            "2  1  7  264.999990     2  0.666667\n",
            "3  1  7  267.518090     3  0.750000\n",
            "4  0  7  269.904530     3  0.600000\n",
            "-----------------------\n",
            "Total Number of episodes:  13795\n",
            "Average Episodic Reward: 0.4428416092787242\n",
            "Mean Episode Length: 7.2\n",
            "----------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Mean Episodic Reward')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFv-iDKr6ilK"
      },
      "source": [
        "### Multi-processing\n",
        "- It appears the SAC does not support multi-processing\n",
        "- Currently, I am abandoning this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bia0pR46m0C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "ac248381-e5f0-49dd-b552-9273562a225e"
      },
      "source": [
        "import os\n",
        "import pybullet as p\n",
        "import imageio\n",
        "import gym\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, SubprocVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "p.connect(p.DIRECT)   # required for google colab\n",
        "\n",
        "\n",
        "\n",
        "# Create directories for saving data\n",
        "root_path = '/content/gdrive/My Drive/Colab/SB3/kuka/'\n",
        "best_model_path = root_path + 'best_model/kuka_mp/'\n",
        "eval_path = root_path + 'eval_results/kuka_mp/'\n",
        "checkpt_path = root_path + 'checkpoints/kuka_mp/'\n",
        "monitor_path = root_path + 'monitor/kuka_mp/'\n",
        "tb_log_path = root_path + 'tb_log/'\n",
        "\n",
        "os.makedirs(best_model_path, exist_ok=True)\n",
        "os.makedirs(eval_path, exist_ok=True)\n",
        "os.makedirs(checkpt_path, exist_ok=True)\n",
        "os.makedirs(monitor_path, exist_ok=True)\n",
        "\n",
        "\n",
        "env_id = NormalizeObsvnWrapper\n",
        "env_kwargs = dict(\n",
        "    env = KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                          removeHeightHack=False)\n",
        ")\n",
        "vec_env = make_vec_env(env_id, n_envs=4, monitor_dir=monitor_path, env_kwargs=env_kwargs)\n",
        "\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class = CustomCNN,\n",
        "    features_extractor_kwargs = dict(features_dim=64),\n",
        "    net_arch = dict(qf=[128, 64, 32], pi=[128, 64, 64])\n",
        ")\n",
        "\n",
        "\n",
        "model = SAC('CnnPolicy', vec_env, buffer_size=70000, batch_size=256,\n",
        "            policy_kwargs=policy_kwargs, tensorboard_log=tb_log_path)\n",
        "\n",
        "# train the model: 50K time steps is adequate\n",
        "begin = datetime.now()\n",
        "model.learn(total_timesteps=50000, log_interval=4, tb_log_name='kuka_sac_mp'), \n",
        "end = datetime.now()\n",
        "print('Training time: ', end - begin)\n",
        "\n",
        "\n",
        "p.disconnect(p.DIRECT)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-755f0f448b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m model = SAC('CnnPolicy', vec_env, buffer_size=70000, batch_size=256,\n\u001b[0;32m---> 48\u001b[0;31m             policy_kwargs=policy_kwargs, tensorboard_log=tb_log_path)\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# train the model: 50K time steps is adequate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, ent_coef, target_update_interval, target_entropy, use_sde, sde_sample_freq, use_sde_at_warmup, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0muse_sde_at_warmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_sde_at_warmup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0moptimize_memory_usage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimize_memory_usage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         )\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, policy_base, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, tensorboard_log, verbose, device, support_multi_env, create_eval_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, remove_time_limit_termination, supported_action_spaces)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0muse_sde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_sde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0msde_sample_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msde_sample_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, policy_base, learning_rate, policy_kwargs, tensorboard_log, verbose, device, support_multi_env, create_eval_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupport_multi_env\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_envs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0;34m\"Error: the model does not support multiple envs; it requires \"\u001b[0m \u001b[0;34m\"a single vectorized environment.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 )\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error: the model does not support multiple envs; it requires a single vectorized environment."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBQ0ND6zmuit",
        "outputId": "641be691-6343-4816-d406-fbc13b05ef83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "import os\n",
        "import pybullet as p\n",
        "import imageio\n",
        "import gym\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, SubprocVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "p.connect(p.DIRECT)   # required for google colab\n",
        "\n",
        "\n",
        "\n",
        "# Create directories for saving data\n",
        "root_path = '/content/gdrive/My Drive/Colab/SB3/kuka/'\n",
        "best_model_path = root_path + 'best_model/kuka_mp/'\n",
        "eval_path = root_path + 'eval_results/kuka_mp/'\n",
        "checkpt_path = root_path + 'checkpoints/kuka_mp/'\n",
        "monitor_path = root_path + 'monitor/kuka_mp/'\n",
        "tb_log_path = root_path + 'tb_log/'\n",
        "\n",
        "os.makedirs(best_model_path, exist_ok=True)\n",
        "os.makedirs(eval_path, exist_ok=True)\n",
        "os.makedirs(checkpt_path, exist_ok=True)\n",
        "os.makedirs(monitor_path, exist_ok=True)\n",
        "\n",
        "\n",
        "env = NormalizeObsvnWrapper(KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                          removeHeightHack=False))\n",
        "\n",
        "vec_env = DummyVecEnv([lambda: env])\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class = CustomCNN,\n",
        "    features_extractor_kwargs = dict(features_dim=64),\n",
        "    net_arch = dict(qf=[128, 64, 32], pi=[128, 64, 64])\n",
        ")\n",
        "\n",
        "\n",
        "model = SAC('CnnPolicy', vec_env, buffer_size=70000, batch_size=256,\n",
        "            policy_kwargs=policy_kwargs, tensorboard_log=tb_log_path)\n",
        "\n",
        "# train the model: 50K time steps is adequate\n",
        "begin = datetime.now()\n",
        "model.learn(total_timesteps=50000, log_interval=4, tb_log_name='kuka_sac_mp'), \n",
        "end = datetime.now()\n",
        "print('Training time: ', end - begin)\n",
        "\n",
        "\n",
        "p.disconnect(p.DIRECT)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1e6763e0cb4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# train the model: 50K time steps is adequate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mbegin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kuka_sac_mp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         )\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mlearning_starts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_starts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             )\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                 \u001b[0;31m# Rescale and perform action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                 \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-64fdafb8354a>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mnew_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modify_obsvn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channel_first'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pybullet_envs/bullet/kuka_diverse_object_gym_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_step_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pybullet_envs/bullet/kuka_diverse_object_gym_env.py\u001b[0m in \u001b[0;36m_step_continuous\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mgrasp_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinger_angle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kuka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplyAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrasp_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepSimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;31m#if self._renders:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m#  time.sleep(self._timeStep)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syoWQ_fp5MuZ"
      },
      "source": [
        "import pybullet as p\n",
        "import imageio\n",
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pybullet_envs.bullet.racecarZEDGymEnv import RacecarZEDGymEnv\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "p.connect(p.DIRECT)\n",
        "\n",
        "\n",
        "#env = RacecarZEDGymEnv(isDiscrete=False, renders=False)\n",
        "#env = DummyVecEnv([lambda: RacecarZEDGymEnv(isDiscrete=False, renders=False)])\n",
        "#env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
        "\n",
        "env = KukaDiverseObjectEnv(renders=False, isDiscrete=False, maxSteps=20,\n",
        "                           removeHeightHack=False)\n",
        "env = DummyVecEnv([lambda: KukaDiverseObjectEnv(renders=False, isDiscrete=False, maxSteps=20,\n",
        "                           removeHeightHack=False)])\n",
        "env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.0)\n",
        "\n",
        "print('shape of Observation space: ', env.observation_space.shape)\n",
        "print('shape of Action space: ', env.action_space.shape)\n",
        "print('Reward Range: ', env.reward_range)\n",
        "print('Action High value: ', env.action_space.high)\n",
        "print('Action Low Value: ', env.action_space.low)\n",
        "\n",
        "policy_kwargs = dict(qf=[128, 128] pi=[64, 64])\n",
        "feature_extractor_kwargs\n",
        "\n",
        "cnn_policy = stable_baselines3.sac.CNNPolicy()\n",
        "# create RL model\n",
        "model = SAC('CnnPolicy', env, verbose=0, buffer_size=10000)\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "print(f'Mean reward before training: {mean_reward:.2f} +/- {std_reward:.2f}')\n",
        "\n",
        "# Train model\n",
        "model.learn(total_timesteps=1000)\n",
        "\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "print(f'Mean reward before training: {mean_reward:.2f} +/- {std_reward:.2f}')\n",
        "\n",
        "\n",
        "# save the model\n",
        "model.save('racecar_sac')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBP488gMc0-R"
      },
      "source": [
        "## PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bvdHoDrDF0w"
      },
      "source": [
        "### Single Process Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucORy8n4DHjE"
      },
      "source": [
        "import os\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "import pybullet as p\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "p.connect(p.DIRECT)\n",
        "\n",
        "# Create directories for saving data\n",
        "root_path = '/content/gdrive/My Drive/Colab/SB3/kuka/'\n",
        "best_model_path = root_path + 'best_model/ppo/'\n",
        "eval_path = root_path + 'eval_results/ppo/'\n",
        "checkpt_path = root_path + 'checkpoints/ppo/'\n",
        "monitor_path = root_path + 'monitor/ppo/'\n",
        "\n",
        "os.makedirs(best_model_path, exist_ok=True)\n",
        "os.makedirs(eval_path, exist_ok=True)\n",
        "os.makedirs(checkpt_path, exist_ok=True)\n",
        "os.makedirs(monitor_path, exist_ok=True)\n",
        "\n",
        "\n",
        "# create the environment\n",
        "env = NormalizeObsvnWrapper(KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                          removeHeightHack=False))\n",
        "\n",
        "env = Monitor(env, monitor_path)\n",
        "\n",
        "# environment for periodic evaluation\n",
        "eval_env = NormalizeObsvnWrapper(KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                          removeHeightHack=False))\n",
        "eval_env = Monitor(eval_env, monitor_path)\n",
        "\n",
        "#callbacks\n",
        "eval_callback = EvalCallback(eval_env, best_model_save_path=root_path+'best_model/',\n",
        "                             log_path=root_path+'eval_results/', eval_freq=500,\n",
        "                             deterministic=True, render=False)\n",
        "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path=checkpt_path, name_prefix='kuka_ppo_chkpt')\n",
        "callback_list = CallbackList([checkpoint_callback, eval_callback])\n",
        "\n",
        "\n",
        "# Custom policy arguments\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class = CustomCNN,\n",
        "    features_extractor_kwargs = dict(features_dim=64),\n",
        "    net_arch = [128, dict(vf=[128, 64, 32], pi=[128, 64, 64])]    # check PPO documentation\n",
        ")\n",
        "\n",
        "# Create PPO model \n",
        "model = PPO('CnnPolicy', env, n_steps=100000, batch_size=256,\n",
        "            policy_kwargs=policy_kwargs, tensorboard_log=tb_log_path)\n",
        "\n",
        "# train the model: 50K time steps is adequate\n",
        "%time model.learn(total_timesteps=50000, log_interval=4, tb_log_name='kuka_ppo', callback=callback_list)\n",
        "\n",
        "mean, std = evaluate_policy(model, env, n_eval_episodes=50, deterministic=True)\n",
        "print('Evaluate the model after training: {} +/- {}'.format(mean, std))\n",
        "\n",
        "p.disconnect(p.DIRECT)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSdifRLVHBtS"
      },
      "source": [
        "### Multi-process Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jdYsx2lc0A7",
        "outputId": "98963c45-6126-4e94-d849-eb9b3770ee1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "import pybullet as p\n",
        "from pybullet_envs.bullet.kuka_diverse_object_gym_env import KukaDiverseObjectEnv\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, CallbackList\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from datetime import datetime\n",
        "p.connect(p.DIRECT)\n",
        "\n",
        "\n",
        "# Create directories for saving data\n",
        "root_path = '/content/gdrive/My Drive/Colab/SB3/kuka/'\n",
        "best_model_path = root_path + 'best_model/ppo_mp/'\n",
        "eval_path = root_path + 'eval_results/ppo_mp/'\n",
        "checkpt_path = root_path + 'checkpoints/ppo_mp/'\n",
        "monitor_path = root_path + 'monitor/ppo_mp/'\n",
        "tb_log_path = root_path + 'tb_log/'\n",
        "\n",
        "os.makedirs(best_model_path, exist_ok=True)\n",
        "os.makedirs(eval_path, exist_ok=True)\n",
        "os.makedirs(checkpt_path, exist_ok=True)\n",
        "os.makedirs(monitor_path, exist_ok=True)\n",
        "os.makedirs(tb_log_path, exist_ok=True)\n",
        "\n",
        "env_id = NormalizeObsvnWrapper\n",
        "# env_id = KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "#                           removeHeightHack=False)\n",
        "env_kwargs = dict(\n",
        "    env = KukaDiverseObjectEnv(maxSteps=20, isDiscrete=False, renders=False,\n",
        "                          removeHeightHack=False)\n",
        ")\n",
        "vec_env = make_vec_env(env_id, n_envs=2, monitor_dir=monitor_path, env_kwargs=env_kwargs)\n",
        "\n",
        "#eval_vec_env = make_vec_env(env_id, n_envs=1, env_kwargs=env_kwargs)\n",
        "#callbacks\n",
        "\n",
        "# eval_callback = EvalCallback(eval_vec_env, best_model_save_path=best_model_path,\n",
        "#                              log_path=eval_path, eval_freq=1000,\n",
        "#                              deterministic=True, render=False)\n",
        "# checkpoint_callback = CheckpointCallback(save_freq=5000, save_path=checkpt_path, name_prefix='kuka_ppo_checkpt')\n",
        "# callback_list = CallbackList([checkpoint_callback, eval_callback])\n",
        "\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    features_extractor_class = CustomCNN,\n",
        "    features_extractor_kwargs = dict(features_dim=64),\n",
        "    net_arch = [128, dict(vf=[128, 64, 32], pi=[128, 64, 64])]    # check PPO documentation\n",
        ")\n",
        "\n",
        "model = PPO('CnnPolicy', vec_env, n_steps=2048, batch_size=64,\n",
        "            policy_kwargs=policy_kwargs, tensorboard_log=tb_log_path)\n",
        "\n",
        "# train the model: 50K time steps is adequate\n",
        "\n",
        "begin = datetime.now()\n",
        "#model.learn(total_timesteps=50000, log_interval=4, tb_log_name='kuka_ppo_mp', callback=eval_callback)\n",
        "model.learn(total_timesteps=50000, log_interval=4, tb_log_name='kuka_ppo_mp')\n",
        "end = datetime.now()\n",
        "print('Training time: ', end-begin)\n",
        "\n",
        "mean, std = evaluate_policy(model, env, n_eval_episodes=50, deterministic=True)\n",
        "print('Evaluate the model after training: {} +/- {}'.format(mean, std))\n",
        "\n",
        "p.disconnect(p.DIRECT)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7e65570c23c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mbegin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#model.learn(total_timesteps=50000, log_interval=4, tb_log_name='kuka_ppo_mp', callback=eval_callback)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kuka_ppo_mp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-64fdafb8354a>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mnew_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modify_obsvn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channel_first'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pybullet_envs/bullet/kuka_diverse_object_gym_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_step_continuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pybullet_envs/bullet/kuka_diverse_object_gym_env.py\u001b[0m in \u001b[0;36m_step_continuous\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mgrasp_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinger_angle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kuka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplyAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrasp_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepSimulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;31m#if self._renders:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m#  time.sleep(self._timeStep)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJcZjnLr5lkq"
      },
      "source": [
        "\n",
        "env_id = KukaDiverseObjectEnv\n",
        "\n",
        "env_kwargs = dict(\n",
        "    maxSteps=20, \n",
        "    isDiscrete=False, \n",
        "    renders=False,\n",
        "    removeHeightHack=False\n",
        ")\n",
        "\n",
        "vec_env = make_vec_env(env_id, n_envs=2, monitor_dir=monitor_path, env_kwargs=env_kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlELsJ28tfID"
      },
      "source": [
        "# Trying VSCODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhJd614wyjWM",
        "outputId": "2e0bc0cd-af53-4004-9235-c1a91f4380b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install colabcode > /dev/null 2>&1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colabcode\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/90/f635c37e8e87cb9df76873edd35068e7b10cd20ac0ba4d2392ae7f307fe9/colabcode-0.3.0-py3-none-any.whl\n",
            "Collecting uvicorn==0.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (45kB)\n",
            "\u001b[K     || 51kB 6.2MB/s \n",
            "\u001b[?25hCollecting pyngrok>=5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/4e/a2fe095bbe17cf26424c4abcd22a0490e22d01cc628f25af5e220ddbf6f0/pyngrok-5.0.5.tar.gz (745kB)\n",
            "\u001b[K     || 747kB 20.9MB/s \n",
            "\u001b[?25hCollecting jupyterlab==3.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/27/149c258b8e80552ba1ad35636eca308776a284cb151cb8fcfff70adfbd0a/jupyterlab-3.0.7-py3-none-any.whl (8.3MB)\n",
            "\u001b[K     || 8.3MB 24.8MB/s \n",
            "\u001b[?25hCollecting nest-asyncio==1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/33/10805a3359f56ac4f3b520e64b9d5e6a288d87be95777b8023c64cba60f1/nest_asyncio-1.4.3-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (3.7.4.3)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n",
            "Collecting h11>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/0f/7a0eeea938eaf61074f29fed9717f2010e8d0e0905d36b38d3275a1e4622/h11-0.12.0-py3-none-any.whl (54kB)\n",
            "\u001b[K     || 61kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok>=5.0.0->colabcode) (3.13)\n",
            "Collecting jupyter-server~=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/b7/7377d007118f7798b21362a6c0a0bf20c93cdc19345105276a862e1263d6/jupyter_server-1.9.0-py3-none-any.whl (389kB)\n",
            "\u001b[K     || 399kB 38.1MB/s \n",
            "\u001b[?25hCollecting jupyterlab-server~=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/6f/a1cfff58e6bc195dce93d17332ba05a9d1691171912ed9a19e943927173a/jupyterlab_server-2.6.1-py3-none-any.whl (56kB)\n",
            "\u001b[K     || 61kB 8.8MB/s \n",
            "\u001b[?25hCollecting tornado>=6.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/a8/9c5902233fa3c2e6a889cbd164333ddda5009669f494e3fadbeee2c03af5/tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428kB)\n",
            "\u001b[K     || 430kB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (4.7.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (20.9)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.11.3)\n",
            "Collecting nbclassic~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/11/68/217ab6d4e4676dcfa4e855bb435469164a361a58e1856872cb06277f14b5/nbclassic-0.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.11.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Collecting jupyter-client>=6.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/e8/c3cf72a32a697256608d5fa96360c431adec6e1c6709ba7f13f99ff5ee04/jupyter_client-6.1.12-py3-none-any.whl (112kB)\n",
            "\u001b[K     || 122kB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.7.1)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.10.1)\n",
            "Collecting requests-unixsocket\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/63/97662a6f7175c08381447a09f6bc35464075f0ea6549cf6daf2668b51f04/requests_unixsocket-0.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.6.1)\n",
            "Collecting anyio<4,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/8c/6712b0aebe9b250736ec5dde99883b143290b49ecc2310eb583577e316aa/anyio-3.2.1-py3-none-any.whl (75kB)\n",
            "\u001b[K     || 81kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.0.5)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.1.3)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (20.1.0)\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/5f/3c211d168b2e9f9342cfb53bcfc26aab0eac63b998015e7af7bcae66119d/websocket_client-1.1.0-py2.py3-none-any.whl (68kB)\n",
            "\u001b[K     || 71kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (22.1.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.9.1)\n",
            "Collecting json5\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/8e/ebde0a31c71e7098b3014faf46c80bdbcadb3c23b0ac7c7646b2af7d302e/json5-0.9.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.23.0)\n",
            "Collecting jsonschema>=3.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/8f/51e89ce52a085483359217bc72cdbf6e75ee595d5b1d4b5ade40c7e018b8/jsonschema-3.2.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     || 61kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (57.0.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->jupyterlab==3.0.7->colabcode) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (2.0.1)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.8.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.0)\n",
            "Requirement already satisfied: urllib3>=1.8 in /usr/local/lib/python3.7/dist-packages (from requests-unixsocket->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.24.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (3.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.10)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.14.5)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.6.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (21.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.0.7->colabcode) (0.2.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (4.10.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.4.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.5-cp37-none-any.whl size=19262 sha256=451412d90e71704f3c0a435a9a9df29df4df8833e427f7df22dc30fd74457c98\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/13/64/5ebbcc22eaf53fdf5766b397c1fb17c83f5775fdccf0ea1b88\n",
            "Successfully built pyngrok\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: h11, uvicorn, pyngrok, tornado, jupyter-client, requests-unixsocket, sniffio, anyio, websocket-client, jupyter-server, json5, jsonschema, jupyterlab-server, nbclassic, jupyterlab, nest-asyncio, colabcode\n",
            "  Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Found existing installation: jupyter-client 5.3.5\n",
            "    Uninstalling jupyter-client-5.3.5:\n",
            "      Successfully uninstalled jupyter-client-5.3.5\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Found existing installation: nest-asyncio 1.5.1\n",
            "    Uninstalling nest-asyncio-1.5.1:\n",
            "      Successfully uninstalled nest-asyncio-1.5.1\n",
            "Successfully installed anyio-3.2.1 colabcode-0.3.0 h11-0.12.0 json5-0.9.6 jsonschema-3.2.0 jupyter-client-6.1.12 jupyter-server-1.9.0 jupyterlab-3.0.7 jupyterlab-server-2.6.1 nbclassic-0.3.1 nest-asyncio-1.4.3 pyngrok-5.0.5 requests-unixsocket-0.2.0 sniffio-1.2.0 tornado-6.1 uvicorn-0.13.1 websocket-client-1.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jupyter_client",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s0TpeO2yyiv",
        "outputId": "06329868-19ca-4864-e0c2-4e88f5a6df50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "from colabcode import ColabCode\n",
        "#ColabCode(port=10000, password=\"password123\")\n",
        "ColabCode()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Code Server can be accessed on: NgrokTunnel: \"https://6bb3c8cdb430.ngrok.io\" -> \"http://localhost:10000\"\n",
            "[2021-07-10T14:22:27.133Z] info  code-server 3.10.2 387b12ef4ca404ffd39d84834e1f0776e9e3c005\n",
            "[2021-07-10T14:22:27.135Z] info  Using user-data-dir ~/.local/share/code-server\n",
            "[2021-07-10T14:22:27.148Z] info  Using config file ~/.config/code-server/config.yaml\n",
            "[2021-07-10T14:22:27.148Z] info  HTTP server listening on http://127.0.0.1:10000 \n",
            "[2021-07-10T14:22:27.148Z] info    - Authentication is disabled \n",
            "[2021-07-10T14:22:27.148Z] info    - Not serving HTTPS \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2d0615fa89b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolabcode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColabCode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#ColabCode(port=10000, password=\"password123\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mColabCode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/colabcode/code.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, port, password, authtoken, mount_drive, code, lab)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_install_extensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/colabcode/code.py\u001b[0m in \u001b[0;36m_run_code\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0muniversal_newlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         ) as proc:\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}